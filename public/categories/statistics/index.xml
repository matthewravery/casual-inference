<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Statistics on Casual Inference</title>
    <link>/categories/statistics/</link>
    <description>Recent content in Statistics on Casual Inference</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 16 Feb 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/statistics/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>DIY Metrics</title>
      <link>/post/diy-metrics/</link>
      <pubDate>Sat, 16 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/diy-metrics/</guid>
      <description>In order to better understand some “advanced metrics”, I figured it’d be useful to build them from scratch. (This is also just a fun exercise in data manipulation, cleaning, etc.)
For starters, let’s do something easy, namely raw plus/minus. For the code below, I’m using the free example play-by-play data set from NBAstuffer. They seem reputable, though I do have concerns about how widely-used their formatting is; one of the challenges with building a workflow is ensuring that the structure of your incoming data won’t change.</description>
    </item>
    
    <item>
      <title>The Arrogance of &#34;Noise&#34;</title>
      <link>/post/the-arrogance-of-noise/</link>
      <pubDate>Sat, 02 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/the-arrogance-of-noise/</guid>
      <description>This is a post about communication.
One of the through-lines of my academic and professional career is conflict between entrenched subject matter experts (SME) and hot-shot quantitative analysts. As a young undergraduate, I followed Baseball Prospectus Fangraphs through the SABRmetric revolution. I watched Nate Silver bring data-driven prognostication to the world of political journalism which had previously (and arguably still is) dominated by punditry. In my current job, I work with experienced analysts who have often been working on the same systems for years.</description>
    </item>
    
    <item>
      <title>Data Science and Data Generation Processes</title>
      <link>/post/data-generation-processes/</link>
      <pubDate>Mon, 28 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/data-generation-processes/</guid>
      <description>I was talking about a curriculum for a new Data Science degree program, and the topic of experimental design came up. Design of Experiments (DOE) is classical subject area for statisticians, and the context of an applied statistics masters degree makes perfect sense, but in the context of data science, it seemed pretty out of place. I say that not because DOE isn&amp;rsquo;t important but because I think its something &amp;ldquo;data science&amp;rdquo; doesn&amp;rsquo;t often consider.</description>
    </item>
    
    <item>
      <title>Calibration update, now with Brier Scores!</title>
      <link>/post/calibration-update/</link>
      <pubDate>Sat, 26 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/calibration-update/</guid>
      <description>After reading my my previous post on calibration, my clever wife (who’s been doing calibration-related activities in the context of modeling and simulation) brought to my attention the concept of Brier Scores. (Alternatively, here.) This approach was originally proposed to evaluate weather forecasts (“Verification of weather forecasts has been a controversial subject for more than half a century,” so at least we’ve moved on controversial climate forecasts in this half-century.</description>
    </item>
    
    <item>
      <title>Is Scott well-calibrated?</title>
      <link>/post/is-scott-well-calibrated/</link>
      <pubDate>Wed, 23 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/is-scott-well-calibrated/</guid>
      <description>Yesterday, Scott Alexander posted his annual predictions review post. I always enjoy this post because it’s externalized introspection. Scott takes the time to formally look at things he thought, consider how right he was about these things, and consider how it should update his thinking moving forward. Most people don’t do this informally let alone formally!
I want to respond to two things in the post, the latter of which is answering the question Scott only implies of whether he’s well-correlated or not.</description>
    </item>
    
  </channel>
</rss>