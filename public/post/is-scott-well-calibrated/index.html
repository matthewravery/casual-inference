<!DOCTYPE html>
<html class="no-js" lang="en-us">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Is Scott well-calibrated?</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<meta name="generator" content="Hugo 0.51" />
	<meta property="og:title" content="Is Scott well-calibrated?" />
<meta property="og:description" content="Yesterday, Scott Alexander posted his annual predictions review post. I always enjoy this post because it’s externalized introspection. Scott takes the time to formally look at things he thought, consider how right he was about these things, and consider how it should update his thinking moving forward. Most people don’t do this informally let alone formally!
I want to respond to two things in the post, the latter of which is answering the question Scott only implies of whether he’s well-correlated or not." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/post/is-scott-well-calibrated/" /><meta property="article:published_time" content="2019-01-23T00:00:00&#43;00:00"/>
<meta property="article:modified_time" content="2019-01-23T00:00:00&#43;00:00"/>

	
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">
	<link rel="stylesheet" href="/css/style.css">
	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container">
		<div class="logo">
			<a class="logo__link" href="/" title="Casual Inference" rel="home">
				<div class="logo__title">Casual Inference</div>
				<div class="logo__tagline">Robust and relaxed</div>
			</a>
		</div>
		
<nav class="menu">
	<button class="menu__btn" aria-haspopup="true" aria-expanded="false" tabindex="0">
		<span class="menu__btn-title" tabindex="-1">Menu</span>
	</button>
	<ul class="menu__list">
		<li class="menu__item">
			<a class="menu__link" href="/">Home</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/post/about/">About</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="https://matthewravery.github.io/markdown-cv">CV</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="https://github.com/jthaman/ciTools">ciTools</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/post/analysis-statement/">Analysis Philosophy</a>
		</li>
	</ul>
</nav>

	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Is Scott well-calibrated?</h1>
			<div class="post__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg>
	<time class="meta__text" datetime="2019-01-23T00:00:00">January 23, 2019</time>
</div>

<div class="meta__item-categories meta__item">
	<svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg>
	<span class="meta__text"><a class="meta__link" href="/categories/statistics" rel="category">statistics</a></span>
</div>
</div>
		</header><div class="content post__content clearfix">
			


<p>Yesterday, Scott Alexander posted his <a href = "https://slatestarcodex.com/2019/01/22/2018-predictions-calibration-results/">annual predictions review post</a>. I always enjoy this post because it’s externalized introspection. Scott takes the time to formally look at things he thought, consider how right he was about these things, and consider how it should update his thinking moving forward. Most people don’t do this informally let alone formally!</p>
<p>I want to respond to two things in the post, the latter of which is answering the question Scott only implies of whether he’s well-correlated or not. But first, Scott states:</p>
<blockquote>
<p>50% predictions are technically meaningless since I could have written them either way – which makes it surprising I managed to get such an imbalance between right and wrong. I think I’m more wrong than should be statistically possible. I’m not sure what to think about that.</p>
</blockquote>
<p>Scott’s more numerate than most, but I think he’s dead wrong here. An important component of being able to predict is to know what you don’t know and exactly how much you don’t know it. Making an even-odds prediction is saying something concrete and precise about your expectations about the likelihood of an event. (This is related to why <a href = "https://statmodeling.stat.columbia.edu/2013/11/21/hidden-dangers-noninformative-priors/">flat priors aren’t necessarily uninformative</a>.)</p>
<p>Another way to say this is that 50% predictions are critical for evaluating how well-calibrated you are. Scott looks briefly, but I wanted to give it a more thorough treatment. I’m going to embed my R code, because this is a fairly simple analysis, and I know other folks made their own predictions and might want to see how well-calibrated they are.</p>
<div id="chi-squre-goodness-of-fit" class="section level2">
<h2>Chi-Squre Goodness of Fit</h2>
<p>The simplest way to look at calibration is a <a href = "https://en.wikipedia.org/wiki/Goodness_of_fit#Categorical_data">Pearson Goodness of Fit test</a>. You can follow the link to read about it, but basically you sum the squared differences in the Observed value in each bin against the valued you’d Expect under your null hypothesis, scaled by the number expected in each bin. In this case, we’ll use “Scott is properly-calibrated” as our Null.</p>
<p>So, for our data set, we have:</p>
<pre class="r"><code>## Simple Pearson chi-square goodness of fit
ab &lt;- tb %&gt;% 
  mutate(&quot;Observed&quot; = n * p,
         &quot;Expected&quot; = n * bin_numeric / 100) 
ab %&gt;% select(bin, n, Observed, Expected)</code></pre>
<pre><code>## # A tibble: 6 x 4
##   bin       n Observed Expected
##   &lt;chr&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;
## 1 50%      22        6     11  
## 2 60%      15        8      9  
## 3 70%      18       14     12.6
## 4 80%      13       10     10.4
## 5 90%      18       17     16.2
## 6 95%       8        6      7.6</code></pre>
<pre class="r"><code>teststatistic &lt;- ab %&gt;% 
  summarise(&quot;ChiSq&quot; = sum((`Observed` - `Expected`)^2/`Expected`))
pchisq(teststatistic$ChiSq, nrow(tb) - 1, lower.tail = F)</code></pre>
<pre><code>## [1] 0.7106033</code></pre>
<p>The data set provided by Scott is the object, <code>tb</code>. (If you want to see how I got <code>tb</code>, I included the code at the end of the post). The “observed” are the number of predictions in each percentage bin Scott got right, and the “expected” is the product of the number of questions (<code>n</code>) with the probability associated with the bin. So for the 90% bin, Scott got 17 out of 18 questions right, and if he was properly calibrated, he’d get 16.2 questions right on average, or <span class="math inline">\(18 * .9\)</span>.</p>
<p>That p-value’s pretty large, so we fail to find adequate evidence to reject the null hypothesis that Scott is well-calibrated.</p>
<p>But this test is pretty under-powered. We might be able to do better by including past-year data to drive up our sample size, but instead, let’s try a visual approach.</p>
</div>
<div id="simultaneous-prediction-bounds" class="section level2">
<h2>Simultaneous prediction bounds</h2>
<p>Prediction intervals are nice things to use for visualizing the potential uncertainty in our observations. (See <a href = "https://github.com/jthaman/ciTools"> for a lot more!</a>) Here, we can use them to visualize whether Scott’s predictions fall outside the range of what we might expect to see.</p>
<p>A naive way to do this would be to look just at generate prediction bounds for each bin and plot each point independently. However, I want to consider Scott’s calibration across all prediction probabilities simultaneously. This means we’ve got to generate our prediction bounds simultaneously for each probability. The simplest way to do this is a Bonferroni correction:</p>
<p>We’ll use a simple Bonferroni correction to estimate bounds around each probability point such that we should only observe a point outside the bounds less than 5% of the time, assuming Scott’s predictions are properly calibrated.</p>
<p>The code chunk below generates the confidence bounds. They’re based on quantiles from Binomial distributions, with the lower and upper bounds being determined by our chosen <span class="math inline">\(\alpha\)</span>-level (0.05), halved because we want two sides and divided by the number of comparisons (6) for our Bonferroni correction. After that, it’s just plotting.</p>
<pre class="r"><code>tb %&gt;% 
  mutate(lower = qbinom(.05/2/nrow(tb), n, bin_numeric/100)/n,
         upper = qbinom(1 - .05/2/nrow(tb), n, bin_numeric/100)/n) %&gt;% 
  ggplot(aes(x = bin_numeric/100, y = bin_numeric/100, ymin = lower, ymax = upper)) +
  geom_ribbon(alpha = .2) + geom_point(size = 2) + geom_line() +
  geom_point(colour = &quot;red&quot;, aes(y = p), size = 2) +
  theme_bw() + ylab(&quot;True Probability&quot;) + xlab(&quot;Expected Probability&quot;) </code></pre>
<p><img src="/post/2019-01-23-is-scott-well-calibrated_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>The red dots are the actual outcomes from Scott’s predictions last year, and the gray shaded region represents the simultaneous prediction band. Since every dot is in the band, we once again fail to find evidence that Scott is mis-calibrated (at the 95% confidence level)!</p>
<p>Note that the bands aren’t uniform width. Typically, the variance in binomial draws decreases as you move away from <span class="math inline">\(p = 0.5\)</span>, but in this case, we also have different numbers of observations in each bin. This is why you see, for example, the prediction band narrow at <span class="math inline">\(p = 0.9\)</span> and then widen again at <span class="math inline">\(p = 0.95\)</span>; there were 18 predictions that Scott placed into the former bin but only 8 in the latter.</p>
<p>Now, having said that, Bonferroni is notoriously a conservative approach. What would be better would be to look at the joint CDF and build confidence bands off of that somehow.</p>
</div>
<div id="using-the-joint-cdf" class="section level2">
<h2>Using the joint CDF</h2>
<p>This bit is a little dicey, since we’re going to be estimating the probability of the full outcome instead of trying to treat each bin separately and making a post-hoc correction like we did above. In other words, the above approach defined its acceptance regions as, “50% bin between 5 and 17 correct AND 60% bin between 4 and 14 correct AND …”, this approach will define its acceptance region as discrete sets of outcomes across all six bins(“{16, 12, 13, 16, 6}, {4, 11, 12, 16, 8}, ….”). This means accepting cases where a single bin is unlikely but most of the other bins are likely.
To do this, we first have to enumerate all possible combinations:</p>
<p>Then, we estimate the likelihood associated with each of these. We arrange the results in ascending order, from least likely to most likely, taking the cumulative sum of probabilities as we go. This cumulative sum is the p-value associated with each possible outcome!</p>
<pre><code>## # A tibble: 76,114 x 8
##             p `50%` `60%` `70%` `80%` `90%` `95%` `p-value`
##         &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;
##  1 0.00000108    14    11    15     8    17     6    0.0500
##  2 0.00000108    13    11    13     7    17     6    0.0500
##  3 0.00000108    10    13    14    10    18     6    0.0500
##  4 0.00000108    12    13    14    10    18     6    0.0500
##  5 0.00000108     8     8     9    11    18     6    0.0500
##  6 0.00000108    14     8     9    11    18     6    0.0500
##  7 0.00000108     7    11    10    12    13     8    0.0500
##  8 0.00000108    15    11    10    12    13     8    0.0500
##  9 0.00000108    11    11    12     6    15     7    0.0500
## 10 0.00000108     7    10    14    13    17     6    0.0500
## # ... with 76,104 more rows</code></pre>
<p>Finally, we can check the p-value of Scott’s outcome:</p>
<pre class="r"><code>nb %&gt;% 
  bind_cols(tibble(`p-value` = cumsum(nb$p))) %&gt;% 
  filter(`50%` == 6, 
            `60%` == 8, 
            `70%` == 14, 
            `80%` == 10,
            `90%` == 17,
            `95%` == 6)</code></pre>
<pre><code>## # A tibble: 1 x 8
##            p `50%` `60%` `70%` `80%` `90%` `95%` `p-value`
##        &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;
## 1 0.00000201     6     8    14    10    17     6    0.0797</code></pre>
<p>So once again, we fail to reject the null hypothesis that Scott is well-calibrated!</p>
<p>Below, we can see a nice visualization of this hypothesis test, with each candidate within the 95% acceptance region represented as an opaque line. Once again, Scott’s outcome is represented in red.</p>
<p>(As an aside, this plot takes about 3 minutes to draw on my PC due to the hundreds of thousands of lines being drawn.)</p>
<p><img src="/post/2019-01-23-is-scott-well-calibrated_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
</div>
<div id="what-about-bayes" class="section level2">
<h2>What about Bayes?</h2>
<p>So sure, we did a bunch of frequentist calculations and <strong>barely</strong> failed to reject some hypotheses, but surely any good Bayesian would adjust their priors in favor of the idea that Scott is mis-calibrated after seeing these data, right?</p>
<p>Not necessarily, IMO. In fact, a good Bayesian would look back at Scott’s past four years of data and conclude that, hey, he actually does pretty well at this stuff and if anything has generally been too cautious in the past. So keep it up, Scott! And definitely continue to make 50% predictions.</p>
<div id="code-for-generating-the-data-set" class="section level3">
<h3>Code for generating the data set</h3>
<p>This is the code I used to parse Scott’s text. It’s probably not efficient and isn’t very interesting either, but I wanted to include it for completeness:</p>
<pre class="r"><code>library(tidyverse)
tb &lt;- tibble(raw = c(&quot;Of 50% predictions, I got 6 right and 16 wrong, for a score of 27%&quot;,
                     &quot;Of 60% predictions, I got 8 right and 7 wrong, for a score of 53%&quot;,
                     &quot;Of 70% predictions, I got 14 right and 4 wrong, for a score of 78%&quot;,
                     &quot;Of 80% predictions, I got 10 right and 3 wrong, for a score of 77%&quot;,
                     &quot;Of 90% predictions, I got 17 right and 1 wrong, for a score of 94%&quot;,
                     &quot;Of 95% predictions, I got 6 right and 2 wrong, for a score of 75%&quot;)) %&gt;% 
  mutate(bin = str_extract(raw, &quot;[0-9][0-9]%&quot;),
         right_start = str_extract(raw, &quot;\\d{1,3} right&quot;), 
         right = str_extract(right_start, &quot;\\d{1,3}&quot;),
         wrong_start = str_extract(raw, &quot;\\d{1,3} wrong&quot;), 
         wrong = str_extract(wrong_start, &quot;\\d{1,3}&quot;),
         x = as.numeric(right),
         n = x + as.numeric(wrong),
         p = x/n,
         bin_simple = str_extract(bin, &quot;\\d{1,2}&quot;),
         bin_numeric = as.numeric(bin_simple)) %&gt;% 
  select(bin, bin_numeric, right, wrong, x, n, p)</code></pre>
</div>
</div>

		</div>
		
	</article>
</main>


<nav class="post-nav flex">
	<div class="post-nav__item post-nav__item--prev">
		<a class="post-nav__link" href="/post/what-is-random-really/" rel="prev"><span class="post-nav__caption">«&thinsp;Previous</span><p class="post-nav__post-title">What is random, really?</p></a>
	</div>
	<div class="post-nav__item post-nav__item--next">
		<a class="post-nav__link" href="/post/calibration-update/" rel="next"><span class="post-nav__caption">Next&thinsp;»</span><p class="post-nav__post-title">Calibration update, now with Brier Scores!</p></a>
	</div>
</nav>


			</div>
			


    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <aside class="sidebar"><div class="widget-search widget">
	<form class="widget-search__form" role="search" method="get" action="https://google.com/search">
		<label>
			<input class="widget-search__field" type="search" placeholder="SEARCH..." value="" name="q" aria-label="SEARCH...">
		</label>
		<input class="widget-search__submit" type="submit" value="Search">
		<input type="hidden" name="sitesearch" value="/" />
	</form>
</div>
<div class="widget-recent widget">
	<h4 class="widget__title">Recent Posts</h4>
	<div class="widget__content">
		<ul class="widget__list">
			<li class="widget__item"><a class="widget__link" href="/post/nonlinearity/">Nonlinearity</a></li>
			<li class="widget__item"><a class="widget__link" href="/post/diy-metrics-game-logs/">DIY Metrics: Game Logs </a></li>
			<li class="widget__item"><a class="widget__link" href="/post/how-analytics-ruins-sports/">How Analytics Ruins Sports</a></li>
			<li class="widget__item"><a class="widget__link" href="/post/ml-invent-metadata/">ML Invents Metadata</a></li>
			<li class="widget__item"><a class="widget__link" href="/post/diy-metrics-simple-stats-and-game-logs/">DIY Metrics:  Counting up simple statistics</a></li>
		</ul>
	</div>
</div>
<div class="widget-categories widget">
	<h4 class="widget__title">Categories</h4>
	<div class="widget__content">
		<ul class="widget__list">
			<li class="widget__item"><a class="widget__link" href="/categories/basketball">Basketball</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/common-analysis-errors">Common analysis errors</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/data-generation">Data generation</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/diymetrics">Diymetrics</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/failure-to-communicate">Failure to communicate</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/hot-takes">Hot takes</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/life-is-distributional">Life is distributional</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/metrics">Metrics</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/misc">Misc</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/ml-invents">Ml invents</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/picking-at-nits">Picking at nits</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/r">R</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/r-diymetrics">R diymetrics</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/sports">Sports</a></li>
			<li class="widget__item"><a class="widget__link" href="/categories/statistics">Statistics</a></li>
		</ul>
	</div>
</div>
</aside>
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2019 Casual Inference.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
	</div>
<script async defer src="/js/menu.js"></script></body>
</html>