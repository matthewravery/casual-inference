---
title: Quick nones on binomial confidence intervals in R
author: Matthew Avery
date: '2020-02-01'
slug: binom-confint
categories:
  - R
  - statistics
tags: []
description: ''
thumbnail: ''
---



<p>I’m teaching a graduate-level intro stats course right now, and one thing that struck me as we move from calculating things “by hand” to doing things in <code>R</code> is that there’s no real reason to emphasize the normal approximation binomail confidence interval once you’re using software. Or at least far less reason.</p>
<div id="the-normal-approximation" class="section level2">
<h2>The normal approximation</h2>
<p>This is the basic interval they’ve taught in introductory statistics courses since time immamorial. Or at least the past few decades, I’d have to know the history of Stats Ed to give the real timeframe. Anyway, this confidence interval uses the fact from the Central Limit Theorem, that, as <span class="math inline">\(n \rightarrow \infty\)</span>, the sampling distribution for <span class="math inline">\(\hat\pi = x/n\)</span> closely resembles a Normal distribution.</p>
<p>Based on that, you get the equation:</p>
<p><span class="math display">\[\hat\pi \pm z_{\frac{\alpha}{2}} \sqrt{\frac{\hat\pi (1 - \hat\pi)}{n}}\]</span></p>
<div id="analog-ci" class="section level3">
<h3>Analog CI</h3>
<p>We can build this CI in R pretty easily by inputting the values for the sample size, <span class="math inline">\(n\)</span>, and the number of “successes” or “1”s from our binary response variable. One example from class discusses a poll of 2500 people with 400 responding “Satisfactory”. For a 90% confidence interval, we have:</p>
<pre class="r"><code>n &lt;- 2500
x &lt;- 400
pihat &lt;- x/n
alpha &lt;- 0.1 # 90% CI --&gt; alpha = 1 - .9 = 0.1

lower_bound &lt;- pihat + qnorm(alpha/2) * sqrt((pihat * (1 - pihat)/n))
upper_bound &lt;- pihat + qnorm(1 - alpha/2) * sqrt((pihat * (1 - pihat)/n))

c(lower_bound, upper_bound)</code></pre>
<pre><code>## [1] 0.1479397 0.1720603</code></pre>
</div>
<div id="easy-mode" class="section level3">
<h3>Easy mode</h3>
<p>But it’s much easier to just use the <code>binom</code> library, which contains the function <code>binom.confint()</code>:</p>
<pre class="r"><code># install.packages(&quot;binom&quot;)
library(binom)

binom.confint(x = 400, n = 2500, conf.level = 0.9, method = &quot;asymptotic&quot;)</code></pre>
<pre><code>##       method   x    n mean     lower     upper
## 1 asymptotic 400 2500 0.16 0.1479397 0.1720603</code></pre>
<p>Much easier! But now that we’re using <code>binom.confint()</code>, we discover that we have to specify <code>method = "asymptotic"</code>. But that implies that there are alternatives! And indeed, if we just remove that statement, we see that there are almost a DOZEN different methods that <code>binom.confint()</code> will compute for you!</p>
</div>
</div>
<div id="other-types-of-binomial-confidence-intervals" class="section level2">
<h2>Other types of binomial confidence intervals</h2>
<p>First off, most of these aren’t useful in most cases. They’re in there because (1) they’re not very hard to program, so the authors figured, “Why not?” and (2) in most cases, there <em>is</em> at least one circumstance where each one is the best option. (Or they’re included for historical reasons.)</p>
<div id="exact-cis-aka-clopper-pearson" class="section level3">
<h3>Exact CIs, aka Clopper-Pearson</h3>
<p>For one simple example, recall the assumption that we always have to make for our Normal approximation method: <span class="math inline">\(n * \hat\pi &gt; 5\)</span> and <span class="math inline">\(n * (1 - \hat\pi) &gt; 5\)</span>. This is required when we use the Normal approximation. It means we can’t build CIs for small-ish samples. But other methods don’t have this problem!</p>
<p><code>method = "exact"</code> uses what’s called the <a href = "https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval#Clopper%E2%80%93Pearson_interval">Clopper-Pearson method</a>, which uses the Binomial distribution to calculate an “exact” confidence interval rather than rely on an approximation.</p>
<p>While being “exact” sounds better than “approximate”, the truth of the matter is that the Clopper-Pearson interval is generally wider than it needs to be, meaning you get a less precise interval:</p>
<pre class="r"><code>library(dplyr)

binom.confint(x = 400, n = 2500, conf.level = 0.9) %&gt;% 
  mutate(`CI Width` = upper - lower) %&gt;% 
  select(method, lower, upper, `CI Width`) %&gt;% 
  arrange(`CI Width`)</code></pre>
<pre><code>##           method     lower     upper   CI Width
## 1          bayes 0.1480550 0.1721635 0.02410856
## 2        cloglog 0.1481500 0.1722628 0.02411279
## 3        profile 0.1481871 0.1723036 0.02411651
## 4         wilson 0.1483082 0.1724269 0.02411870
## 5         probit 0.1482369 0.1723573 0.02412042
## 6     asymptotic 0.1479397 0.1720603 0.02412053
## 7          logit 0.1483044 0.1724312 0.02412679
## 8  agresti-coull 0.1483026 0.1724325 0.02412988
## 9            lrt 0.1481877 0.1723265 0.02413880
## 10         exact 0.1480388 0.1725544 0.02451559
## 11     prop.test 0.1459601 0.1750977 0.02913765</code></pre>
<p>Since we have a large sample, the differences aren’t very large, but there are times when you want every ounce of precision you can get!</p>
</div>
<div id="bayesian-intervals" class="section level3">
<h3>Bayesian intervals</h3>
<p><a href = "https://en.wikipedia.org/wiki/Bayesian_statistics">Bayesian statistics</a> is a school of thought that says we should try to incorporate our prior knowledge about a problem when making a decision instead of letting the data stand on its own.I don’t want to get into why some folks prefer Bayesian intervals, but if you want to, just specify <code>method = "bayes"</code> to get a Bayesian CI.</p>
</div>
<div id="a-good-general-use-ci" class="section level3">
<h3>A good general-use CI</h3>
<p>My go-to for a simple binomial confidence interval is the <a href = "https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval#Agresti%E2%80%93Coull_interval">Agresti-Coull method</a>, <code>method = "agresti-coull"</code>. It’s one of the weirder ones (Seriously, go look at the equation for it!), but generally performs as well or better than the competition across most scenarios. It’s more precise than <code>method = "exact"</code>, doesn’t fail in small samples like <code>method = "asymptotic"</code>, and doesn’t rely on a Bayesian approach.</p>
</div>
</div>
